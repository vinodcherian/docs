{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"DL/DL1/","title":"From Deep Learning MindMap[brief doc]","text":""},{"location":"DL/DL1/#deep-learning-briefing-document","title":"Deep Learning Briefing Document","text":""},{"location":"DL/DL1/#i-introduction-to-deep-learning-concepts","title":"I. Introduction to Deep Learning Concepts","text":"<p>Deep Learning is a subset of machine learning that employs artificial neural networks with multiple layers to learn representations of data with multiple levels of abstraction. This briefing outlines key concepts, components, and methodologies within deep learning, drawing from the provided \"Deep Learning mindmap.pdf\" source.</p>"},{"location":"DL/DL1/#ii-core-components-of-a-neural-network","title":"II. Core Components of a Neural Network","text":""},{"location":"DL/DL1/#a-layers","title":"A. Layers","text":"<p>Neural networks are structured in layers, which are the fundamental building blocks.</p> <ul> <li>Input Layer: \"Comprised of multiple Real-Valued inputs. Each input must be linearly independent from each other.\" This layer receives the initial data.</li> <li>Hidden Layers: These are \"Layers other than the input and output layers.\" A layer \"usually receives weighted input, transforms it with a set of mostly non-linear functions and then passes these values as output to the next layer.\" The presence of multiple hidden layers is what defines \"deep\" learning.</li> <li>Output Layer: This layer produces the final output of the network, based on the transformations performed by the preceding layers.</li> </ul>"},{"location":"DL/DL1/#b-weight-initialization","title":"B. Weight Initialization","text":"<p>Proper initialization of weights is crucial for effective training.</p> <ul> <li>All Zero Initialization: This is a \"mistake\" because \"if every neuron in the network computes the same output, then they will also all compute the same gradients during back-propagation and undergo the exact same parameter updates.\" This leads to a lack of asymmetry and prevents neurons from learning distinct features.</li> <li>Initialization with Small Random Numbers: This is the preferred method, as it ensures \"neurons are all random and unique in the beginning, so they will compute distinct updates and integrate themselves as diverse parts of the full network.\" Values are typically drawn from a normal distribution with zero mean and small standard deviation.</li> <li>Calibrating the Variances: To ensure consistent output distribution across neurons and improve convergence, \"you can normalize the variance of each neuron's output to 1 by scaling its weight vector by the square root of its fan-in (i.e., its number of inputs).\"</li> </ul>"},{"location":"DL/DL1/#c-activation-functions","title":"C. Activation Functions","text":"<p>An activation function \"Defines the output of that node given an input or set of inputs.\" They introduce non-linearity into the network, enabling it to learn complex patterns. Common types include:</p> <ul> <li>ReLU (Rectified Linear Unit)</li> <li>Sigmoid / Logistic</li> <li>Tanh</li> <li>Softmax</li> <li>Leaky ReLU, PReLU, RReLU, ELU, SELU, and others.</li> </ul>"},{"location":"DL/DL1/#iii-training-and-optimization","title":"III. Training and Optimization","text":""},{"location":"DL/DL1/#a-costloss-functions","title":"A. Cost/Loss Functions","text":"<p>Cost or Loss functions quantify the error of a model's predictions compared to the true values. The goal of training is to minimize this function.</p> <ul> <li>Maximum Likelihood Estimation (MLE): Many cost functions, such as Least Squares and Cross-Entropy, are derived from MLE. It selects \"the set of values of the model parameters that maximizes the likelihood function,\" intuitively maximizing \"the 'agreement' of the selected model with the observed data.\" The natural logarithm of the likelihood function (log-likelihood) is often used for convenience due to its monotonic increasing nature.</li> <li>Cross-Entropy: Used to define the loss function, where \"The true probability pi is the true label, and the given distribution qi is the predicted value of the current model.\" It's particularly common in classification tasks.</li> <li>Quadratic Loss: \"Common, for example when using least squares techniques.\" It is \"more mathematically tractable than other loss functions\" and is symmetric, meaning errors of the same magnitude above or below the target result in the same loss.</li> <li>0-1 Loss: A simple function that assigns 0 if the prediction is correct and 1 if it's incorrect.</li> <li>Hinge Loss: Used for training classifiers, particularly for Support Vector Machines.</li> <li>Exponential Loss: Another function used in classification.</li> <li>Hellinger Distance: Quantifies the similarity between two probability distributions.</li> <li>Kullback-Leibler Divergence: Measures \"how one probability distribution diverges from a second expected probability distribution.\" It's used for information gain and characterizing entropy.</li> </ul>"},{"location":"DL/DL1/#b-optimization-algorithms","title":"B. Optimization Algorithms","text":"<p>Optimization algorithms adjust the model's parameters to minimize the loss function.</p> <ul> <li>Gradient Descent: A \"first-order iterative optimization algorithm for finding the minimum of a function.\" It involves taking \"steps proportional to the negative of the gradient.\"</li> <li>Stochastic Gradient Descent (SGD): While standard Gradient Descent uses the \"total gradient over all examples per update,\" SGD \"updates after only 1 or few examples.\" \"Ordinary gradient descent as a batch method is very slow, should never be used.\"</li> <li>Mini-batch Stochastic Gradient Descent (SGD): The \"most commonly used now,\" it updates using a \"mini-batch x1...m of size m\" of examples, typically between 20 and 1000. This balances the estimation quality of the gradient with computational efficiency due to parallelism.</li> <li>Momentum: Improves SGD by \"Add[ing] a fraction v of previous update to current one.\" This \"will increase the size of the steps taken towards the minimum\" when the gradient consistently points in the same direction.</li> <li>Adagrad: Provides \"Adaptive learning rates for each parameter!\" This means \"learning rate is adapting differently for each parameter and rare parameters get larger updates than frequently occurring parameters.\"</li> <li>Learning Rate: A crucial hyperparameter that dictates the step size taken during gradient descent. If too high, weights \"will change far too much each iteration, which will make them 'overcorrect' and the loss will actually increase/diverge.\" Common strategies include keeping it fixed, reducing it by 0.5 when validation error stops improving, or using adaptive methods like AdaGrad.</li> </ul>"},{"location":"DL/DL1/#c-backpropagation","title":"C. Backpropagation","text":"<p>\"Is a method used in artificial neural networks to calculate the error contribution of each neuron after a batch of data. It calculates the gradient of the loss function.\" It's essential for gradient-based optimization algorithms. The error is \"calculated at the output and distributed back through the network layers,\" which is why it's also called \"backward propagation of errors.\" This method is efficient because it \"reuse[s] partial derivatives computed for higher layers in lower layers.\"</p>"},{"location":"DL/DL1/#d-regularization","title":"D. Regularization","text":"<p>Techniques to prevent overfitting, where the model performs well on training data but poorly on unseen data.</p> <ul> <li>L1 Norm (Manhattan Distance): Also known as Least Absolute Deviations (LAD), it minimizes \"the sum of the absolute differences (S) between the target value and the estimated values.\" It can lead to sparse models.</li> <li>L2 Norm (Euclidean Distance): Also known as Least Squares, it minimizes \"the sum of the square of the differences (S) between the target value and the estimated values.\"</li> <li>Early Stopping: Provides \"guidance as to how many iterations can be run before the learner begins to over-fit, and stop the algorithm then.\" Using \"parameters that gave best validation error.\"</li> <li>Dropout: A \"regularization technique for reducing overfitting in neural networks by preventing complex co-adaptations on training data.\" During training, \"randomly set 50% of the inputs to each neuron to 0.\" At test time, \"halve the model weights.\" This acts as a form of model averaging.</li> <li>Sparse Regularizer on Columns: Combines L2 norm on each column with an L1 norm over all columns.</li> <li>Nuclear Norm Regularization: Not detailed, but listed as a type.</li> <li>Mean-Constrained Regularization: \"Constrains the functions learned for each task to be similar to the overall average of the functions across all tasks,\" useful when tasks are expected to share similarities.</li> </ul>"},{"location":"DL/DL1/#iv-neural-network-architectures","title":"IV. Neural Network Architectures","text":""},{"location":"DL/DL1/#a-feed-forward-neural-networks","title":"A. Feed-Forward Neural Networks","text":"<p>In these networks, \"connections between the units do not form a cycle.\" Information moves \"only in one direction, forward, from the input nodes, through the hidden nodes (if any) and to the output nodes.\"</p> <ul> <li>Single-Layer Perceptron: Inputs are directly connected to outputs via weights. With a logistic activation function, it becomes a logistic regression model.</li> <li>Multi-Layer Perceptron: Consists of \"multiple layers of computational units, usually interconnected in a feed-forward way.\" Each neuron in one layer connects to neurons in the subsequent layer, often using a sigmoid activation function.</li> </ul>"},{"location":"DL/DL1/#b-recurrent-neural-networks-rnns","title":"B. Recurrent Neural Networks (RNNs)","text":"<p>\"A class of artificial neural network where connections between units form a directed cycle.\" This allows them to \"exhibit dynamic temporal behavior\" and \"use their internal memory to process arbitrary sequences of inputs,\" making them suitable for tasks like handwriting or speech recognition.</p> <ul> <li>Long Short-Term Memory (LSTMs): A specific type of RNN that allows data to flow both forwards and backwards, making it \"well-suited to learn from experience to classify, process and predict time series given time lags of unknown size.\" LSTMs are relatively insensitive to gap length, offering an advantage over other sequence learning methods.</li> </ul>"},{"location":"DL/DL1/#c-recursive-neural-networks-rnns","title":"C. Recursive Neural Networks (RNNs)","text":"<p>\"A kind of deep neural network created by applying the same set of weights recursively over a structure, to produce a structured prediction over variable-size input structures.\" They have been successful in natural language processing for learning sequence and tree structures, particularly continuous representations of phrases and sentences based on word embeddings.</p>"},{"location":"DL/DL1/#d-convolutional-neural-networks-cnns","title":"D. Convolutional Neural Networks (CNNs)","text":"<p>Primarily used for tasks involving grid-like data, such as images. They have applications in \"image and video recognition, recommender systems and natural language processing.\" Key components include:</p> <ul> <li>Convolution: Applying filters to input data to extract features.</li> <li>Pooling/Subsampling: Reducing the spatial dimensions of the feature maps, helping to make the representation more robust to small shifts and distortions.</li> </ul>"},{"location":"DL/DL1/#e-auto-encoders","title":"E. Auto-Encoders","text":"<p>\"An artificial neural network used for unsupervised learning of efficient codings.\" Their aim is \"to learn a representation (encoding) for a set of data, typically for the purpose of dimensionality reduction.\" They are increasingly used for learning generative models.</p>"},{"location":"DL/DL1/#f-generative-adversarial-networks-gans","title":"F. Generative Adversarial Networks (GANs)","text":"<p>\"A class of artificial intelligence algorithms used in unsupervised machine learning, implemented by a system of two neural networks contesting with each other in a zero-sum game framework.\" One network (the generator) creates new data, and the other (the discriminator) tries to distinguish between real and generated data.</p>"},{"location":"DL/DL1/#v-practical-deep-learning-strategy--tools","title":"V. Practical Deep Learning Strategy &amp; Tools","text":""},{"location":"DL/DL1/#a-gradient-checks","title":"A. Gradient Checks","text":"<p>An essential step for debugging neural network implementations.</p> <ol> <li>Implement your gradient.</li> <li>Implement a finite difference computation by adding and subtracting a small epsilon to parameters and estimating derivatives.</li> <li>Compare the two to ensure they are \"almost the same.\" If gradient checks fail, simplify the model until the bug is identified.</li> </ol>"},{"location":"DL/DL1/#b-model-power-and-regularization","title":"B. Model Power and Regularization","text":"<ul> <li>Check if the model is powerful enough to overfit: If not, \"change model structure or make model 'larger'\" by increasing units or layers.</li> <li>If you can overfit: \"Regularize to prevent overfitting.\" Initial steps include \"Reduce model size by lowering number of units and layers\" or applying \"Standard L1 or L2 regularization on weights.\"</li> </ul>"},{"location":"DL/DL1/#c-tensorflow","title":"C. TensorFlow","text":"<p>TensorFlow is a prominent open-source machine learning framework developed by Google. It provides primitives for defining functions on tensors and automatically computing their derivatives, expressed as a graph.</p> <ul> <li>Intuition: The \"Tensorflow Graph is build to contain all placeholders for X and y, all variables for W\u2019s and b\u2019s, all mathematical operations, the cost function, and the optimisation procedure.\" At runtime, data batches are \"fed into that Graph, by placing the data batches in the placeholders and running the Graph.\" This graph-based approach enables parallelization across networks.</li> <li>Main Components:Variables: \"Stateful nodes that output their current value, their state is retained across multiple executions of the graph.\" These are typically parameters like Weights (W) and Biases (b).</li> <li>Placeholders: \"Nodes whose value is fed at execution time,\" typically for inputs (features X and labels y).</li> <li>Mathematical Operations: Functions like MatMul, Add, ReLU.</li> <li>Graph Nodes: Operations with inputs and outputs.</li> <li>Edges: Tensors that flow between nodes.</li> <li>Session: \"A binding to a particular execution context: CPU, GPU.\" It's used to execute operations in the graph.</li> <li>Phases:Construction: Assembling the computational graph (no numerical values yet).</li> <li>Execution: Using a Session object to evaluate tensors and run operations.</li> <li>tf.estimator: TensorFlow's high-level API that simplifies building, training, and evaluating various ML models, including LinearClassifier, LinearRegressor, DNNClassifier, and DNNRegressor.</li> <li>Main Steps for tf.estimator:Define Feature Columns: Encoding features for Estimators (e.g., real_valued_column for continuous, sparse_column_with_* for categorical).</li> <li>Define your Layers, or use a prebuilt model.</li> <li>Write the input_fn function: Holds features and labels.</li> <li>Train the model using the fit function.</li> <li>Predict and Evaluate using eval_input_fn.</li> <li>TensorBoard: \"TensorFlow has some neat built-in visualization tools (TensorBoard)\" for monitoring and visualizing training processes.</li> </ul>"},{"location":"DL/DL2/","title":"From Deep Learning MindMap","text":"<p>Here is the information from the sources, structured into a hierarchical tree with bullet points as requested:</p> <ol> <li>Concepts a. Input Layer i. Comprised of multiple Real-Valued inputs. ii. Each input must be linearly independent from each other. b. Hidden Layers i. Layers other than the input and output layers. ii. A layer is the highest-level building block in deep learning. iii. A layer usually receives weighted input, transforms it with mostly non-linear functions, and passes these values as output to the next layer. c. Batch Normalization i. Using mini-batches of examples is helpful. ii. The gradient of the loss over a mini-batch is an estimate of the gradient over the training set, and its quality improves as the batch size increases. iii. Computation over a batch can be much more efficient due to the parallelism afforded by modern computing platforms.</li> <li>Cost/Loss (Min) Objective (Max) Functions a. Maximum Likelihood Estimation (MLE) i. Many cost functions are the result of applying Maximum Likelihood, such as the Least Squares cost function and Cross-Entropy. ii. The likelihood of a parameter value (or vector of parameter values), \u03b8, given outcomes x, is equal to the probability (density) assumed for those observed outcomes given those parameter values. iii. The natural logarithm of the likelihood function, called the log-likelihood, is more convenient to work with.</li> <li>It can be used in place of the likelihood in maximum likelihood estimation because the logarithm is a monotonically increasing function, thus achieving its maximum value at the same points as the function itself. iv. It selects the set of values of the model parameters that maximises the likelihood function for a fixed set of data and underlying statistical model. v. Intuitively, this maximises the \"agreement\" of the selected model with the observed data. vi. For discrete random variables, it maximises the probability of the observed data under the resulting distribution. vii. Maximum-likelihood estimation gives a unified approach to estimation, which is well-defined in the case of the normal distribution and many other problems. b. Cross-Entropy i. Can be used to define the loss function in machine learning and optimization. ii. The true probability p\u1d62 represents the true label. iii. The given distribution q\u1d62 represents the predicted value of the current model. iv. An example is the Cross-entropy error function used with logistic regression. c. Quadratic i. The use of a quadratic loss function is common, for example when using least squares techniques. ii. It is often more mathematically tractable than other loss functions due to the properties of variances. iii. It is symmetric: an error above the target causes the same loss as the same magnitude of error below the target. iv. If the target is t, then a quadratic loss function is defined as a specific formula. d. 0-1 Loss i. In statistics and decision theory, this is a frequently used loss function. e. Hinge Loss i. A loss function used for training classifiers. ii. For an intended output t = \u00b11 and a classifier score y, the hinge loss of the prediction y is defined as a specific formula. f. Exponential g. Hellinger Distance i. Used to quantify the similarity between two probability distributions. ii. It is a type of f-divergence. iii. The square of the Hellinger distance between two probability measures P and Q (absolutely continuous with respect to a third probability measure \u03bb) is defined as a specific quantity. h. Kullback-Leibler Divergence i. Is a measure of how one probability distribution diverges from a second expected probability distribution. ii. Applications include:</li> <li>Characterising the relative (Shannon) entropy in information systems.</li> <li>Randomness in continuous time-series.</li> <li>Information gain when comparing statistical models of inference. iii. Can be applied to Discrete or Continuous distributions. i. Itakura\u2013Saito distance i. Is a measure of the difference between an original spectrum P(\u03c9) and an approximation *P^(\u03c9)* of that spectrum. ii. Although not a perceptual measure, it is intended to reflect perceptual (dis)similarity.</li> <li>Regularization a. L1 norm (Manhattan Distance) i. Also known as least absolute deviations (LAD) or least absolute errors (LAE). ii. It is basically minimizing the sum of the absolute differences (S) between the target value and the estimated values. b. L2 norm (Euclidean Distance) i. Also known as least squares. ii. It is basically minimizing the sum of the square of the differences (S) between the target value and the estimated values. c. Early Stopping i. Early stopping rules provide guidance as to how many iterations can be run before the learner begins to over-fit, and stop the algorithm then. ii. Use parameters that gave the best validation error. d. Dropout i. A regularization technique for reducing overfitting in neural networks. ii. Prevents complex co-adaptations on training data. iii. It is a very efficient way of performing model averaging with neural networks. iv. The term \"dropout\" refers to dropping out units (both hidden and visible) in a neural network. v. During training time: at each instance of evaluation (in online SGD-training), randomly set 50% of the inputs to each neuron to 0. vi. During test time: halve the model weights. vii. This prevents feature co-adaptation, meaning a feature cannot only be useful in the presence of particular other features. e. Sparse regularizer on columns i. This regularizer defines an L2 norm on each column and an L1 norm over all columns. ii. It can be solved by proximal methods. f. Nuclear norm regularization g. Mean-constrained regularization i. This regularizer constrains the functions learned for each task to be similar to the overall average of the functions across all tasks. ii. This is useful for expressing prior information that each task is expected to share similarities with each other task. iii. An example is predicting blood iron levels measured at different times of the day, where each task represents a different person. iv. This regularizer is similar to the mean-constrained regularizer, but instead enforces a different constraint.</li> <li>Weight Initialization a. All Zero Initialization i. In the ideal situation, with proper data normalization, it is reasonable to assume that approximately half of the weights will be positive and half will be negative. ii. Setting all initial weights to zero, expecting it to be the \"best guess\", turns out to be a mistake. iii. If every neuron computes the same output, they will also compute the same gradients during back-propagation and undergo the exact same parameter updates, meaning there is no source of asymmetry between neurons. b. Initialization with Small Random Numbers i. Weights should be very close to zero, but not identically zero. ii. Randomising neurons to small numbers (very close to zero) is treated as symmetry breaking. iii. The idea is that neurons are initially random and unique, so they will compute distinct updates and integrate as diverse parts of the full network. iv. Implementation for weights might simply involve drawing values from a normal distribution with zero mean, and unit standard deviation. v. Using small numbers drawn from a uniform distribution is also possible, but has relatively little impact on final performance in practice. c. Calibrating the Variances i. A problem with small random number initialization is that the distribution of outputs from a randomly initialized neuron has a variance that grows with the number of inputs. ii. This variance can be normalized to 1 by scaling each neuron's weight vector by the square root of its fan-in (its number of inputs). iii. This ensures that all neurons initially have approximately the same output distribution. iv. Empirically, this improves the rate of convergence. v. The derivations for this can be found in pages 18 to 23 of the slides (not provided). vi. Note that the derivations do not consider the influence of ReLU neurons.</li> <li>Optimization a. Gradient Descent i. A first-order iterative optimization algorithm for finding the minimum of a function. ii. To find a local minimum, one takes steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point. iii. If steps are proportional to the positive of the gradient, one approaches a local maximum; this is known as gradient ascent. iv. Uses the total gradient over all examples per update. v. Ordinary gradient descent as a batch method is very slow and should never be used. b. Stochastic Gradient Descent (SGD) i. With SGD, training proceeds in steps, considering a mini-batch x1...m of size *m* at each step. ii. The mini-batch is used to approximate the gradient of the loss function with respect to the parameters. iii. Updates after only 1 or a few examples. iv. On large datasets, SGD usually wins over all batch methods. c. Mini-batch Stochastic Gradient Descent (SGD) i. Most commonly used now. ii. Size of each mini-batch B typically ranges from 20 to 1000. iii. Helps parallelising any model by computing gradients for multiple elements of the batch in parallel. d. Momentum i. Idea: Add a fraction v of previous update to the current one. ii. When the gradient keeps pointing in the same direction, this will increase the size of the steps taken towards the minimum. iii. Reduce global learning rate when using a lot of momentum. iv. Update Rule: v is initialised at 0. v. Momentum often increased after some epochs (e.g., from 0.5 to 0.99). e. Adagrad i. Provides adaptive learning rates for each parameter. ii. The learning rate adapts differently for each parameter. iii. Rare parameters get larger updates than frequently occurring parameters, which is useful for word vectors. iv. It is a method for not hand-setting learning rates. f. Learning Rate i. Neural networks are often trained by gradient descent on the weights. ii. At each iteration, backpropagation calculates the derivative of the loss function with respect to each weight, which is then subtracted from that weight. iii. If the weights change too much each iteration, they will \"overcorrect\" and the loss will increase/diverge. iv. In practice, people usually multiply each derivative by a small value called the \u201clearning rate\u201d before subtracting it from its corresponding weight. v. Simplest recipe: keep it fixed and use the same for all parameters. vi. Better results by allowing learning rates to decrease.</li> <li>Options include: Reducing by 0.5 when validation error stops improving.</li> <li>Reduction by O(1/t) because of theoretical convergence guarantees, with hyper-parameters \u03b50 and \u03c4 and t as iteration numbers.</li> <li>Backpropagation a. A method used in artificial neural networks to calculate the error contribution of each neuron after a batch of data. b. It calculates the gradient of the loss function. c. It is commonly used in the gradient descent optimization algorithm. d. Also called backward propagation of errors, because the error is calculated at the output and distributed back through the network layers. e. It reuses partial derivatives computed for higher layers in lower layers, for efficiency.</li> <li>Activation Functions a. Defines the output of that node given an input or set of inputs. b. Types include: i. ReLU ii. Sigmoid / Logistic iii. Binary iv. Tanh v. Softplus vi. Softmax vii. Maxout viii. Leaky ReLU, PReLU, RReLU, ELU, SELU, and others.</li> <li>Architectures Strategy a. Check for implementation bugs with gradient checks i. Implement your gradient. ii. Implement a finite difference computation by looping through the network parameters, adding and subtracting a small epsilon (10\u207b\u2074), and estimating derivatives. iii. Compare the two and make sure they are almost the same. iv. If your gradient fails and you don\u2019t know why, simplify your model until you have no bug. v. Create a very tiny synthetic model and dataset. vi. Example progression from simplest to more complex model for debugging:</li> <li>Only softmax on fixed input.</li> <li>Backprop into word vectors and softmax.</li> <li>Add single unit single hidden layer.</li> <li>Add multi unit single layer.</li> <li>Add second layer single unit, then multiple units, bias.</li> <li>Add one softmax on top, then two softmax layers.</li> <li>Add bias. b. Parameter Initialization i. Initialize hidden layer biases to 0. ii. Initialize output (or reconstruction) biases to optimal value if weights were 0 (e.g., mean target or inverse sigmoid of mean target). iii. Initialize weights Uniform(\u2212r, r), where r is inversely proportional to fan-in (previous layer size) and fan-out (next layer size). c. Optimization i. Gradient Descent (as described in section 5.a). ii. Stochastic Gradient Descent (SGD) (as described in section 5.b).</li> <li>Ordinary gradient descent as a batch method is very slow and should never be used; use 2nd order batch methods such as L-BFGS.</li> <li>On large datasets, SGD usually wins over all batch methods.</li> <li>On smaller datasets, L-BFGS or Conjugate Gradients win.</li> <li>Large-batch L-BFGS extends the reach of L-BFGS. iii. Mini-batch Stochastic Gradient Descent (SGD) (as described in section 5.c). iv. Momentum (as described in section 5.d). v. Adagrad (as described in section 5.e). d. Check if the model is powerful enough to overfit i. If not, change model structure or make the model \"larger\". ii. If you can overfit, regularise to prevent overfitting.</li> <li>Simple first step: Reduce model size by lowering the number of units and layers and other parameters.</li> <li>Apply Standard L1 or L2 regularization on weights.</li> <li>Use Early Stopping: parameters that gave the best validation error.</li> <li>Apply Sparsity constraints on hidden activations, e.g., by adding to the cost.</li> <li>Implement Dropout (as described in section 3.d).</li> <li>Neural Network Architectures / Types a. RNNs (Recursive) i. A kind of deep neural network created by applying the same set of weights recursively over a structure. ii. It produces a structured prediction over variable-size input structures, or a scalar prediction, by traversing a given structure in topological order. iii. RNNs have been successful in learning sequence and tree structures in natural language processing, mainly phrase and sentence continuous representations based on word embedding. b. RNNs (Recurrent) i. A class of artificial neural network where connections between units form a directed cycle. ii. This allows them to exhibit dynamic temporal behavior. iii. Unlike feedforward neural networks, RNNs can use their internal memory to process arbitrary sequences of inputs. iv. This makes them applicable to tasks such as unsegmented, connected handwriting recognition or speech recognition. v. LSTMs are a type of recurrent RNN. c. Convolutional Neural Networks (CNN) i. They have applications in image and video recognition, recommender systems, and natural language processing. ii. Key components include:</li> <li>Pooling</li> <li>Convolution</li> <li>Subsampling d. Auto-Encoders i. An artificial neural network used for unsupervised learning of efficient codings. ii. The aim is to learn a representation (encoding) for a set of data, typically for dimensionality reduction. iii. Recently, the autoencoder concept has become more widely used for learning generative models of data. e. GANs (Generative Adversarial Networks) i. A class of artificial intelligence algorithms used in unsupervised machine learning. ii. Implemented by a system of two neural networks contesting with each other in a zero-sum game framework. f. LSTMs (Long Short-Term Memory) i. It is a type of recurrent RNN. ii. Allows data to flow both forwards and backwards within the network. iii. An LSTM is well-suited to learn from experience to classify, process, and predict time series given time lags of unknown size and bound between important events. iv. Relative insensitivity to gap length gives an advantage to LSTM over alternative RNNs, hidden Markov models, and other sequence learning methods in numerous applications. g. Feed Forward i. An artificial neural network wherein connections between the units do not form a cycle. ii. Information moves in only one direction, forward, from the input nodes, through the hidden nodes (if any) and to the output nodes. iii. There are no cycles or loops in the network. iv. Kinds:</li> <li>Single-Layer Perceptron a. The inputs are fed directly to the outputs via a series of weights. b. By adding a Logistic activation function to the outputs, the model is identical to a classical Logistic Regression model.</li> <li>Multi-Layer Perceptron a. This class of networks consists of multiple layers of computational units, usually interconnected in a feed-forward way. b. Each neuron in one layer has directed connections to the neurons of the subsequent layer. c. In many applications, the units of these networks apply a sigmoid function as an activation function.</li> <li>TensorFlow a. Packages i. <code>tf</code> (Main). ii. <code>tf.estimator</code>: TensorFlow\u2019s high-level machine learning API.</li> <li>Makes it easy to configure, train, and evaluate a variety of machine learning models.</li> <li>Includes pre-canned estimators like: a. <code>tf.estimator.LinearClassifier</code>: Constructs a linear classification model. b. <code>tf.estimator.LinearRegressor</code>: Constructs a linear regression model. c. <code>tf.estimator.DNNClassifier</code>: Constructs a neural network classification model. d. <code>tf.estimator.DNNRegressor</code>: Constructs a neural network regression model. e. <code>tf.estimator.DNNLinearCombinedClassifier</code>: Constructs a neural network and linear combined classification model. f. <code>tf.estimator.DNNRegressor</code>: Constructs a neural network and linear combined regression model. b. Main Steps (General) i. Create the Model. ii. Define Target. iii. Define Loss function and Optimizer. iv. Define the Session and Initialise Variables. v. Train the Model. vi. Test Trained Model. c. Main Steps (using <code>tf.estimator</code>) i. Define Feature Columns</li> <li>These are the primary way of encoding features for pre-canned <code>tf.learn</code> Estimators.</li> <li>The type of feature column chosen depends on the feature type and the model type.</li> <li>Continuous Features can be represented by <code>real_valued_column</code>.</li> <li>Categorical Features can be represented by any <code>sparse_column_with_*</code> column (e.g., <code>sparse_column_with_keys</code>, <code>sparse_column_with_vocabulary_file</code>, <code>sparse_column_with_hash_bucket</code>, <code>sparse_column_with_integerized_feature</code>). ii. Define your Layers, or use a prebuilt model (e.g., a pre-built Logistic Regression Classifier). iii. Write the <code>input_fn</code> function</li> <li>This function holds the actual data (features and labels).</li> <li><code>Features</code> is a Python dictionary. iv. Train the model using the <code>fit</code> function, on the <code>input_fn</code>.</li> <li>The feature columns are fed to the model as arguments. v. Predict and Evaluate using the <code>eval_input_fn</code> defined previously. d. Comparison to Numpy i. TensorFlow does lazy evaluation. ii. You need to build the graph, and then run it in a session. e. Main Components i. Variables</li> <li>Stateful nodes that output their current value, with their state retained across multiple executions of the graph.</li> <li>Mostly parameters we\u2019re interested in tuning, such as Weights (W) and Biases (b).</li> <li>They are in-memory buffers containing tensors.</li> <li>Declared variables must be initialised before they have values.</li> <li>When training a model, variables are used to hold and update parameters.</li> <li>Sharing variables can be done by: a. Explicitly passing <code>tf.Variable</code> objects around. b. Implicitly wrapping <code>tf.Variable</code> objects within <code>tf.variable_scope</code> objects. ii. Scopes</li> <li><code>tf.variable_scope()</code>: Provides simple name spacing to avoid cases when querying.</li> <li><code>tf.get_variable()</code>: Creates/Accesses variables from a variable scope. iii. Placeholders</li> <li>Nodes whose value is fed at execution time.</li> <li>Used for Inputs, Features (X) and Labels (y). iv. Mathematical Operations: Examples include <code>MatMul</code>, <code>Add</code>, <code>ReLU</code>, etc.. v. Graph Nodes: They are Operations, containing any number of inputs and outputs. vi. Edges: The tensors that flow between the nodes. vii. Session</li> <li>It is a binding to a particular execution context: CPU, GPU.</li> <li>A Session object encapsulates the environment in which Tensor objects are evaluated.</li> <li>Uses a session to execute operations (<code>ops</code>) in the graph.</li> <li>Running a Session involves: a. Inputs. b. Fetches: A list of graph nodes, returning the output of these nodes. c. Feeds: A dictionary mapping from graph nodes to concrete values, specifying the value of each graph node given in the dictionary. f. Phases i. Construction: Assembles a computational graph.</li> <li>The computation graph has no numerical value until evaluated.</li> <li>All computations add nodes to the global default graph. ii. Execution: A Session object encapsulates the environment in which Tensor objects are evaluated.</li> <li>Uses a session to execute <code>ops</code> in the graph. g. TensorBoard: TensorFlow has some neat built-in visualisation tools. h. Intuition i. Google provides primitives for defining functions on tensors and automatically computing their derivatives, expressed as a graph. ii. The TensorFlow Graph is built to contain all placeholders for X and y, all variables for W\u2019s and b\u2019s, all mathematical operations, the cost function, and the optimisation procedure. iii. At runtime, the values for the data are fed into that Graph, by placing the data batches in the placeholders and running the Graph. iv. Each node in the Graph can then be connected to each other node over the network, allowing TensorFlow models to be parallelised.</li> </ol>"},{"location":"ML/Data_Science/","title":"Data Science","text":"<ul> <li>Web Scraping<ol> <li>Beautiful Soup</li> <li>Scrapy</li> <li>UrlLib</li> </ol> </li> <li>Data Visualization<ol> <li>Tableau</li> <li>PowerBI</li> <li>Matplotlib</li> <li>GGplot</li> <li>Seaborn</li> </ol> </li> <li>Programming Language<ol> <li>Python</li> <li>R</li> <li>Java</li> <li>DotNet</li> <li>Julia</li> </ol> </li> <li>Data Analysis<ol> <li>Feature Engineering</li> <li>Data Wrangling</li> <li>EDA</li> <li>Deploy</li> <li>AWS</li> <li>Azure</li> <li>Google Engine</li> </ol> </li> <li>IDE / Editor<ol> <li>Pycharm</li> <li>Jupyter</li> <li>Google Colab</li> <li>Spyder</li> <li>RStudio</li> <li>Visual Studio</li> <li>VS code</li> </ol> </li> <li>Math<ol> <li>Statistics</li> <li>Linear Algebra</li> <li>Differential Calculus</li> </ol> </li> <li> <p>Machine Learning</p> <ol> <li>Reinforcement Learning - (State and Action)<ol> <li>Genetic Algorithm</li> <li>Deep Q-Network (DQN)</li> <li>SARSA</li> <li>A3C</li> <li>Model-Free<ol> <li>Q-Learning</li> <li>Hybrid</li> <li>Policy Optimization</li> </ol> </li> <li>Model-Based<ol> <li>Learn the Model</li> <li>Given the Model</li> </ol> </li> </ol> </li> <li> <p>Classical Learning</p> <ol> <li> <p>Supervised - (Data with Label)</p> <ol> <li> <p>Regression</p> <ol> <li>Linear Regression</li> <li>Polynomial Regression</li> <li>Ridge / Lasso Regression</li> <li>Stepwise Regression</li> <li>Ordinary Least Squares Regression</li> </ol> <p>Example : Stock Market Prediction, Rainfall Prediction</p> </li> <li> <p>Classification</p> <ol> <li>K-Nearest Neighbor (K-NN)</li> <li>Na\u00efve Bayes Classifier</li> <li>Support Vector Machine (SVM)</li> <li>Decision Trees</li> <li>Logistic Regression</li> </ol> <p>Example: Email Spam Detection, Speech Recognition</p> </li> </ol> </li> <li> <p>Unsupervised - (Data without Label)</p> <ol> <li>Hidden Markov Model</li> <li> <p>Clustering - [Continuous]</p> <ol> <li>Hierarchical Clustering</li> <li>Agglornerative</li> <li>DBSCAN</li> <li>K-Means</li> <li>K-Median</li> <li>SVD</li> <li>Principal Component Analysis (PCA)</li> <li>Expection Maximization</li> <li>Mean-Shift</li> <li>Fuzzy C-Means</li> </ol> <p>Example: Identifying Fake News, Document Analysis</p> </li> <li> <p>Association Analysis / Pattern Search</p> <ol> <li>Euclat</li> <li>Apriori</li> <li>FP-Growth</li> </ol> <p>Example: Market Basket Analysis</p> </li> <li> <p>Dimension Reduction (Generalization)</p> <ol> <li>t-SNE</li> <li>LSA</li> <li>SVD</li> <li>LDA</li> <li>Principal Component Analysis (PCA) - [Feature Extraction]</li> <li>Wrapper - [Feature Selection]</li> <li>Filter- [Feature Selection]</li> <li>Embedded Method- [Feature Selection]</li> </ol> <p>Example: Analysis of written texts and DNA microarray data</p> </li> </ol> </li> </ol> </li> <li> <p>Ensemble Methods</p> <ol> <li>Bagging<ol> <li>Random Forest</li> </ol> </li> <li>Stacking</li> <li>Boosting<ol> <li>AdaBoost</li> <li>CatBoost</li> <li>XGBoost</li> <li>LightGBM</li> </ol> </li> </ol> </li> <li>Neural Network and Deep Learning<ol> <li>Perceptrons (MLP)</li> <li>CNN<ol> <li>DCNN</li> </ol> </li> <li>RNN<ol> <li>LSM</li> <li>LSTM</li> <li>GRU</li> </ol> </li> <li>AutoEncoders</li> <li>Seq2Seq</li> <li>Generative Adversarial Networks (GAN)</li> </ol> </li> </ol> </li> </ul>"},{"location":"ML/evaluation/","title":"Model Evaluation","text":""},{"location":"ML/evaluation/#regression-metrics","title":"Regression Metrics","text":"<ul> <li>MAE</li> <li>MSE</li> <li>RMSE</li> </ul>"},{"location":"ML/evaluation/#confusion-matrix","title":"Confusion Matrix","text":""},{"location":"ML/evaluation/#classification-metrics","title":"Classification Metrics","text":"<ul> <li>Accuracy</li> <li>Precision</li> <li>Recall</li> <li>F1 score</li> </ul>"},{"location":"ML/model_comparision/","title":"Machine Learning Algorithms Comparision","text":"<ul> <li>ML Model Name</li> <li>Assumptions</li> <li>Advantages</li> <li>Disadvantages</li> <li>Feature Scaling</li> <li>Missing Data</li> <li>Outliers</li> <li>Suitable for Problem like classification etc</li> <li>Learning Type like supervised etc</li> <li>Example use Real /world</li> </ul>"},{"location":"ML/types_of_ML/","title":"Types of ML","text":""},{"location":"ML/types_of_ML/#types-of-machine-learning-algorithms","title":"Types of machine learning algorithms:","text":"<ul> <li>Supervised Machine Learning</li> <li>Unsupervised Machine Learning</li> <li>Reinforcement Learning <p>Semi-Supervised Learning and Self-Supervised Learning, which combines elements of both supervised and unsupervised learning.</p> </li> </ul>"},{"location":"ML/types_of_ML/#supervised-machine-learning","title":"Supervised Machine Learning","text":"<ul> <li>Classification<ul> <li>Logistic Regression</li> <li>Decision Tree</li> <li>Random Forest</li> <li>K-Nearest Neighbors (KNN)</li> <li>Naive Bayes</li> <li>Support Vector Machine</li> </ul> </li> <li>Regression<ul> <li>Linear Regression</li> <li>Polynomial Regression</li> <li>Ridge Regression</li> <li>Lasso Regression</li> <li>Decision tree</li> <li>Random Forest</li> </ul> </li> </ul>"},{"location":"ML/types_of_ML/#unsupervised-machine-learning","title":"Unsupervised Machine Learning","text":"<ul> <li>Clustering<ul> <li>K-Means</li> <li>DBSCAN</li> <li>Mean-shift</li> </ul> </li> <li>Dimensionality Reduction Techniques<ul> <li>Principal Component Analysis</li> <li>Independent Component Analysis</li> </ul> </li> <li>Association Rule Learning<ul> <li>Apriori</li> <li>FP-growth</li> <li>Eclat</li> </ul> </li> </ul>"},{"location":"ML/types_of_ML/#1-supervised-learning-algorithms","title":"1\ufe0f\u20e3 Supervised Learning Algorithms","text":""},{"location":"ML/types_of_ML/#-a-regression-algorithms","title":"\ud83d\udd39 A. Regression Algorithms","text":"<p>Used for predicting continuous values.</p> <ul> <li>Linear Regression</li> <li>Polynomial Regression</li> <li>Ridge Regression</li> <li>Lasso Regression</li> <li>Elastic Net</li> <li>Support Vector Regression (SVR)</li> <li>Decision Tree Regression</li> <li>Random Forest Regression</li> <li>Gradient Boosting Regression</li> <li>AdaBoost Regression</li> <li>XGBoost Regression</li> <li>LightGBM Regression</li> <li>CatBoost Regression</li> <li>Bayesian Linear Regression</li> <li>Quantile Regression</li> </ul>"},{"location":"ML/types_of_ML/#-b-classification-algorithms","title":"\ud83d\udd39 B. Classification Algorithms","text":"<p>Used for predicting categorical labels.</p> <ul> <li>Logistic Regression</li> <li>K-Nearest Neighbors (KNN)</li> <li>Support Vector Machine (SVM)</li> <li>Decision Tree</li> <li>Random Forest</li> <li>Naive Bayes (Gaussian, Multinomial, Bernoulli)</li> <li>Gradient Boosting</li> <li>AdaBoost</li> <li>XGBoost</li> <li>LightGBM</li> <li>CatBoost</li> <li>Stochastic Gradient Descent (SGD) Classifier</li> <li>Perceptron</li> <li>Passive Aggressive Classifier</li> <li>Neural Networks (MLP)</li> <li>Quadratic Discriminant Analysis (QDA)</li> <li>Linear Discriminant Analysis (LDA)</li> </ul>"},{"location":"ML/types_of_ML/#2-unsupervised-learning-algorithms","title":"2\ufe0f\u20e3 Unsupervised Learning Algorithms","text":""},{"location":"ML/types_of_ML/#-a-clustering","title":"\ud83d\udd39 A. Clustering","text":"<ul> <li>K-Means</li> <li>K-Medoids</li> <li>Hierarchical Clustering</li> <li>DBSCAN</li> <li>HDBSCAN</li> <li>OPTICS</li> <li>Mean Shift</li> <li>Gaussian Mixture Models (GMM)</li> <li>Spectral Clustering</li> <li>Affinity Propagation</li> <li>Birch Clustering</li> </ul>"},{"location":"ML/types_of_ML/#-b-dimensionality-reduction","title":"\ud83d\udd39 B. Dimensionality Reduction","text":"<ul> <li>Principal Component Analysis (PCA)</li> <li>Kernel PCA</li> <li>Linear Discriminant Analysis (for reduction)</li> <li>t-SNE</li> <li>UMAP</li> <li>Independent Component Analysis (ICA)</li> <li>Factor Analysis</li> <li>Autoencoders</li> </ul>"},{"location":"ML/types_of_ML/#-c-association-rule-learning","title":"\ud83d\udd39 C. Association Rule Learning","text":"<ul> <li>Apriori Algorithm</li> <li>Eclat Algorithm</li> <li>FP-Growth</li> </ul>"},{"location":"ML/types_of_ML/#3-semi-supervised-learning","title":"3\ufe0f\u20e3 Semi-Supervised Learning","text":"<ul> <li>Self-Training</li> <li>Label Propagation</li> <li>Label Spreading</li> <li>Co-Training</li> <li>Semi-Supervised SVM</li> </ul>"},{"location":"ML/types_of_ML/#4-reinforcement-learning-algorithms","title":"4\ufe0f\u20e3 Reinforcement Learning Algorithms","text":""},{"location":"ML/types_of_ML/#-a-value-based-methods","title":"\ud83d\udd39 A. Value-Based Methods","text":"<ul> <li>Q-Learning</li> <li>SARSA</li> <li>Deep Q Network (DQN)</li> <li>Double DQN</li> <li>Dueling DQN</li> </ul>"},{"location":"ML/types_of_ML/#-b-policy-based-methods","title":"\ud83d\udd39 B. Policy-Based Methods","text":"<ul> <li>REINFORCE</li> <li>Policy Gradient</li> <li>Proximal Policy Optimization (PPO)</li> <li>Trust Region Policy Optimization (TRPO)</li> </ul>"},{"location":"ML/types_of_ML/#-c-actor-critic-methods","title":"\ud83d\udd39 C. Actor-Critic Methods","text":"<ul> <li>A2C (Advantage Actor-Critic)</li> <li>A3C (Asynchronous Advantage Actor-Critic)</li> <li>Deep Deterministic Policy Gradient (DDPG)</li> <li>Twin Delayed DDPG (TD3)</li> <li>Soft Actor-Critic (SAC)</li> </ul>"},{"location":"ML/types_of_ML/#5-deep-learning-algorithms--architectures","title":"5\ufe0f\u20e3 Deep Learning Algorithms / Architectures","text":"<ul> <li>Artificial Neural Networks (ANN)</li> <li>Convolutional Neural Networks (CNN)</li> <li>Recurrent Neural Networks (RNN)</li> <li>LSTM (Long Short-Term Memory)</li> <li>GRU (Gated Recurrent Unit)</li> <li>Transformer</li> <li>BERT</li> <li>GPT</li> <li>Autoencoders</li> <li>Variational Autoencoders (VAE)</li> <li>Generative Adversarial Networks (GAN)</li> <li>Diffusion Models</li> </ul>"},{"location":"ML/types_of_ML/#6-ensemble-methods","title":"6\ufe0f\u20e3 Ensemble Methods","text":"<ul> <li>Bagging</li> <li>Boosting</li> <li>Stacking</li> <li>Voting Classifier</li> <li>Random Forest</li> <li>Gradient Boosting</li> </ul>"},{"location":"ML/types_of_ML/#7-probabilistic--graphical-models","title":"7\ufe0f\u20e3 Probabilistic / Graphical Models","text":"<ul> <li>Hidden Markov Models (HMM)</li> <li>Conditional Random Fields (CRF)</li> <li>Bayesian Networks</li> <li>Markov Random Fields</li> <li>Latent Dirichlet Allocation (LDA \u2013 Topic Modeling)</li> </ul>"},{"location":"ML/types_of_ML/#8-evolutionary--optimization-based-ml","title":"8\ufe0f\u20e3 Evolutionary &amp; Optimization-Based ML","text":"<ul> <li>Genetic Algorithms</li> <li>Genetic Programming</li> <li>Particle Swarm Optimization</li> <li>Ant Colony Optimization</li> <li>Differential Evolution</li> <li>Simulated Annealing</li> </ul>"},{"location":"ML/types_of_ML/#9-specialized-algorithms","title":"9\ufe0f\u20e3 Specialized Algorithms","text":""},{"location":"ML/types_of_ML/#-recommender-systems","title":"\ud83d\udd39 Recommender Systems","text":"<ul> <li>Collaborative Filtering</li> <li>Matrix Factorization</li> <li>SVD</li> <li>Neural Collaborative Filtering</li> </ul>"},{"location":"ML/types_of_ML/#-anomaly-detection","title":"\ud83d\udd39 Anomaly Detection","text":"<ul> <li>Isolation Forest</li> <li>One-Class SVM</li> <li>Local Outlier Factor (LOF)</li> <li>Autoencoder-based Detection</li> </ul>"},{"location":"ML/types_of_ML/#-instance-based-learning","title":"\ud83d\udd1f Instance-Based Learning","text":"<ul> <li>K-Nearest Neighbors</li> <li>Learning Vector Quantization (LVQ)</li> </ul>"}]}